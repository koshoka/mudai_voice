# 次回のアクション

**最終更新**: 2025-10-04
**現在の状態**: Phase 3実装完了・動作テスト保留中

---

## 優先度1: 文字起こしファイルを開く機能の修正

### 問題
メニューバーの「最後の文字起こしを開く」ボタンを押しても何も起こらない。

### 実施手順

#### ステップ1: 問題原因の調査

```bash
# AppDelegate.swiftで該当メニュー項目の実装を確認
# 予想される問題箇所: openLastTranscription() メソッド
```

確認すべきポイント:
- [ ] メソッドが実装されているか
- [ ] ファイルパスが正しく取得できているか
- [ ] NSWorkspace.shared.open() が正しく呼ばれているか
- [ ] エラーログが出ているか

#### ステップ2: 修正実装

予想される修正内容:
```swift
// AppDelegate.swift内
func openLastTranscription() {
    // 最新の文字起こしファイル（.md）を取得
    // NSWorkspaceで開く
    // エラーハンドリング追加
}
```

参考:
- 既存の `openLastRecording()` メソッドの実装を参照
- FileStorageServiceの使用方法を確認

#### ステップ3: 動作確認

テスト手順:
1. アプリ起動
2. 録音実施（マイクがあれば文字起こしまで）
3. メニューバーから「最後の文字起こしを開く」をクリック
4. Finderで.mdファイルが開くことを確認

---

## 優先度2: マイクを使った文字起こし機能の動作確認

### 前提条件
- マイクが接続されている
- WhisperKitの初回モデルダウンロードには時間がかかる
  - Small: 約500MB
  - Medium: 約1.5GB
  - 安定したインターネット接続が必要

### テスト手順

#### テスト1: 基本的な文字起こしフロー

1. **アプリ起動**
   ```bash
   # Xcodeから実行
   ⌘+R
   ```

2. **設定確認**
   - メニューバー → 設定
   - 「自動文字起こし」がONになっているか確認
   - Whisperモデル: まずは「Small」で試す（軽量・高速）

3. **録音実施**
   - メニューバー → 録音開始
   - 日本語で話す（例: 「これはテストです。今日は良い天気です。」）
   - 5〜10秒程度録音
   - メニューバー → 録音停止

4. **確認ポイント**
   - [ ] 「録音完了」通知が表示される
   - [ ] 数秒〜数十秒後に「文字起こし完了」通知が表示される
   - [ ] 通知から「Finderで開く」をクリック
   - [ ] .mdファイルが開く
   - [ ] 文字起こしテキストが表示される

#### テスト2: Mediumモデルの比較

1. 設定画面でWhisperモデルを「Medium」に変更
2. 同じ内容を録音
3. 精度の違いを確認
4. 処理時間の違いを確認

#### テスト3: 英語の文字起こし

1. 英語で録音（例: "This is a test. The weather is nice today."）
2. 文字起こし結果を確認
3. 精度を評価

### トラブルシューティング

#### 初回実行時のモデルダウンロード

もし処理が長時間かかる場合:
- Console.appでログを確認
  - フィルタ: "VoiceCapture"
  - "Downloading model" などのメッセージを確認
- ネットワーク接続を確認
- 初回のみ10〜30分かかる可能性あり

#### 文字起こし失敗時

確認すべき点:
- [ ] macOS 15.0以降を使用しているか
- [ ] ディスク容量は十分か（モデル分 + 録音ファイル分）
- [ ] マイク権限が許可されているか
- [ ] Console.appでエラーログを確認

---

## 優先度3: マイク選択機能の実装（将来対応）

### 現状
- UI表示のみ
- 実際の録音には反映されない
- 理由: AVAudioRecorderは特定デバイス指定に非対応

### 実装に必要なこと

#### ステップ1: AudioRecordingServiceのリファクタリング

変更内容:
```
AVAudioRecorder ベース
↓
AVAudioEngine + AVCaptureDevice ベース
```

影響範囲:
- AudioRecordingService.swift 全体
- 録音処理の完全な書き換え
- テストの再実施

推定工数: 4〜6時間

#### ステップ2: テスト実施

確認項目:
- [ ] デフォルトマイクでの録音
- [ ] 外部マイクでの録音
- [ ] iPhone Mirroring経由のマイク
- [ ] 音質の確認
- [ ] ファイルサイズの比較

### 優先度判断

**推奨**: Phase 4（UX改善）の後に実施

理由:
- 現在の録音機能は正常動作している
- マイク選択は「あると便利」だが必須ではない
- UX改善（進捗表示、エラーハンドリング）の方が優先度高い

---

## 参考: 現在の実装状態

### 完了している機能
- ✅ 録音開始/停止
- ✅ WAVファイル保存
- ✅ グローバルホットキー（Option + P）
- ✅ 設定画面UI
- ✅ 音声品質カスタマイズ
- ✅ 保存先ディレクトリ選択
- ✅ WhisperKit統合
- ✅ 文字起こしサービス実装
- ✅ Markdown出力
- ✅ 通知機能

### 既知の問題
- ❌ 文字起こしファイルを開く機能が動作しない
- ⚠️ マイク選択がUI表示のみ（実装未完）

### 未確認項目（マイク不在のため）
- ⏸ 実際の文字起こし動作
- ⏸ Whisperモデルダウンロード
- ⏸ 文字起こし精度
- ⏸ パフォーマンス

---

## 次回の作業開始時のチェックリスト

### 準備
- [ ] `/Users/kk/development/mudai_voice/PROGRESS.md` を確認
- [ ] このファイル（NEXT_STEPS.md）を確認
- [ ] Xcodeでプロジェクトを開く
- [ ] マイクを接続（文字起こしテストする場合）

### 推奨作業順序
1. 「文字起こしファイルを開く」機能の修正（30分〜1時間）
2. マイクを使った文字起こしテスト（1〜2時間、モデルDL込み）
3. バグ修正・UX改善（必要に応じて）

### いつでも確認できる情報
- **詳細な進捗**: `/Users/kk/development/mudai_voice/PROGRESS.md`
- **Phase 3実装詳細**: `/Users/kk/development/mudai_voice/VoiceCapture/PHASE3_IMPLEMENTATION_SUMMARY.md`
- **セットアップ手順**: `/Users/kk/development/mudai_voice/VoiceCapture/PHASE3_SETUP_INSTRUCTIONS.md`

---

**最後のコミット**: `9f24b96 - feat: Phase 3完了 - WhisperKit統合・マイク選択UI実装`
